import asyncio
import time
import logging
from collections import Counter
from dataclasses import dataclass, field
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

@dataclass
class StatsContainer:
    """
    Um contêiner de dados para armazenar métricas de desempenho e custo.
    
    Utiliza propriedades para calcular métricas derivadas sob demanda, garantindo
    que os valores estejam sempre atualizados e evitando a complexidade de
    cálculos manuais em outros locais.
    """
    # --- Identificação e Tempo ---
    id: str
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    # --- Contadores de Requisição ---
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    error_type_counts: Counter = field(default_factory=Counter)
    total_retry_count: int = 0

    # --- Contadores de Tokens e Custo ---
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    total_cached_tokens: int = 0
    total_cost: float = 0.0

    # --- Métricas de Latência ---
    total_api_response_time: float = 0.0

    # --- Métricas de Rate Limiter ---
    api_rate_limits_detected: int = 0
    proactive_pauses: int = 0
    total_proactive_wait_time: float = 0.0
    global_rate_limit_activations: int = 0
    total_global_wait_time: float = 0.0
    
    # --- Métricas de Concorrência ---
    current_concurrent_requests: int = 0
    concurrent_peak: int = 0
    configured_max_concurrency: int = 0

    # --- Propriedades Calculadas ---
    @property
    def processing_time(self) -> float:
        """Calcula o tempo total de processamento."""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

    @property
    def total_tokens(self) -> int:
        """Calcula o total de tokens (input + output)."""
        return self.total_input_tokens + self.total_output_tokens

    @property
    def avg_rate(self) -> float:
        """Calcula a taxa média de requisições por segundo."""
        if self.processing_time > 0:
            return self.total_requests / self.processing_time
        return 0.0

    @property
    def success_rate(self) -> float:
        """Calcula a porcentagem de requisições bem-sucedidas."""
        if self.total_requests > 0:
            return (self.successful_requests / self.total_requests) * 100
        return 0.0

    @property
    def avg_api_latency(self) -> float:
        """Calcula a latência média da API por requisição."""
        if self.total_requests > 0:
            return self.total_api_response_time / self.total_requests
        return 0.0

    @property
    def avg_cost_per_request(self) -> float:
        """Calcula o custo médio por requisição."""
        if self.total_requests > 0:
            return self.total_cost / self.total_requests
        return 0.0


class StatsManager:
    """
    Gerenciador centralizado para coletar, calcular e apresentar estatísticas.

    Esta classe é a única fonte da verdade para todas as métricas do sistema.
    Ela é responsável por:
    - Rastrear estatísticas globais e por lote (batch).
    - Calcular custos de requisição com base na configuração do modelo.
    - Receber e interpretar eventos do RateLimiter.
    - Fornecer uma formatação clara e informativa das estatísticas.
    """

    def __init__(self, models_config: Dict[str, Any]):
        """
        Inicializa o StatsManager.

        Args:
            models_config (Dict[str, Any]): A configuração carregada de `models.json`,
                                           contendo preços e capacidades dos modelos.
        """
        self._models_config = models_config
        self._global_stats = StatsContainer(id="global")
        self._batch_stats: Dict[str, StatsContainer] = {}
        self._lock = asyncio.Lock()
        logger.info("StatsManager inicializado e pronto para coletar métricas.")

    def _get_model_pricing(self, model: str) -> Dict[str, float]:
        """Obtém os preços de um modelo a partir da configuração carregada."""
        model_data = self._models_config.get(model)
        if not model_data:
            logger.warning(f"Preços para o modelo '{model}' não encontrados. Custo não será calculado.")
            return {'input': 0.0, 'output': 0.0, 'cache': 0.0}
        return {
            'input': model_data.get('input', 0.0),
            'output': model_data.get('output', 0.0),
            'cache': model_data.get('cache', 0.0)
        }

    def _calculate_cost(
        self, model: str, input_tokens: int, output_tokens: int, cached_tokens: int = 0
    ) -> float:
        """
        Calcula o custo total de uma requisição, considerando tokens de input,
        output e cache.
        """
        pricing = self._get_model_pricing(model)
        
        regular_input_tokens = max(0, input_tokens - cached_tokens)
        regular_input_cost = (regular_input_tokens / 1000) * pricing['input']
        cached_cost = (cached_tokens / 1000) * pricing['cache']
        output_cost = (output_tokens / 1000) * pricing['output']
        
        return regular_input_cost + cached_cost + output_cost

    async def _update_stats(self, stats: StatsContainer, **kwargs):
        """Função auxiliar para atualizar um contêiner de estatísticas de forma segura."""
        stats.total_requests += 1
        
        if kwargs.get('success', False):
            stats.successful_requests += 1
        else:
            stats.failed_requests += 1
            error_type = kwargs.get('error_type', 'UnknownError')
            stats.error_type_counts[error_type] += 1
        
        cost = self._calculate_cost(
            model=kwargs['model'],
            input_tokens=kwargs.get('input_tokens', 0),
            output_tokens=kwargs.get('output_tokens', 0),
            cached_tokens=kwargs.get('cached_tokens', 0)
        )
        stats.total_cost += cost

        stats.total_input_tokens += kwargs.get('input_tokens', 0)
        stats.total_output_tokens += kwargs.get('output_tokens', 0)
        stats.total_cached_tokens += kwargs.get('cached_tokens', 0)
        stats.total_api_response_time += kwargs.get('api_response_time', 0.0)
        stats.total_retry_count += kwargs.get('retry_count', 0)

    async def record_request(self, batch_id: Optional[str] = None, **kwargs):
        """
        Registra os dados de uma única requisição finalizada.

        Este é o principal método para alimentar dados no StatsManager.
        Ele atualiza tanto as estatísticas globais quanto as do lote (se aplicável).
        """
        async with self._lock:
            await self._update_stats(self._global_stats, **kwargs)
            if batch_id and batch_id in self._batch_stats:
                await self._update_stats(self._batch_stats[batch_id], **kwargs)

    async def record_rate_limiter_event(self, event: Dict[str, Any], batch_id: Optional[str] = None):
        """
        Registra eventos vindos do RateLimiter para manter as estatísticas precisas.
        """
        event_type = event.get('event_type')
        async with self._lock:
            containers = [self._global_stats]
            if batch_id and batch_id in self._batch_stats:
                containers.append(self._batch_stats[batch_id])

            for stats in containers:
                if event_type == 'proactive_pause':
                    stats.proactive_pauses += 1
                    stats.total_proactive_wait_time += event.get('wait_time', 0.0)
                elif event_type == 'global_pause':
                    stats.global_rate_limit_activations += 1
                    stats.total_global_wait_time += event.get('wait_time', 0.0)
                elif event_type == 'api_rate_limit_detected':
                     stats.api_rate_limits_detected += 1
                elif event_type == 'concurrency_update':
                    stats.configured_max_concurrency = event.get('new_concurrency', 0)
    
    async def record_concurrent_start(self, batch_id: Optional[str] = None):
        """Registra o início de uma requisição para rastrear a concorrência."""
        async with self._lock:
            containers = [self._global_stats]
            if batch_id and batch_id in self._batch_stats:
                containers.append(self._batch_stats[batch_id])
            
            for stats in containers:
                stats.current_concurrent_requests += 1
                if stats.current_concurrent_requests > stats.concurrent_peak:
                    stats.concurrent_peak = stats.current_concurrent_requests

    async def record_concurrent_end(self, batch_id: Optional[str] = None):
        """Registra o fim de uma requisição."""
        async with self._lock:
            containers = [self._global_stats]
            if batch_id and batch_id in self._batch_stats:
                containers.append(self._batch_stats[batch_id])
            
            for stats in containers:
                stats.current_concurrent_requests -= 1

    def start_batch(self, batch_id: str):
        """Inicia um novo contêiner de estatísticas para um lote."""
        if batch_id in self._batch_stats:
            logger.warning(f"Batch com ID '{batch_id}' já existe. Sobrescrevendo estatísticas.")
        
        self._batch_stats[batch_id] = StatsContainer(id=batch_id)
        logger.info(f"Lote de estatísticas '{batch_id}' iniciado.")

    def end_batch(self, batch_id: str) -> Optional[StatsContainer]:
        """Finaliza um lote, registrando o tempo de término."""
        if batch_id in self._batch_stats:
            self._batch_stats[batch_id].end_time = time.time()
            return self._batch_stats[batch_id]
        logger.warning(f"Tentativa de finalizar lote inexistente: '{batch_id}'")
        return None

    def get_global_stats(self) -> StatsContainer:
        """Retorna o contêiner de estatísticas globais."""
        return self._global_stats

    def get_batch_stats(self, batch_id: str) -> Optional[StatsContainer]:
        """Retorna o contêiner de estatísticas de um lote específico."""
        return self._batch_stats.get(batch_id)

    def format_stats(self, stats: StatsContainer, title: str) -> str:
        """Formata um contêiner de estatísticas em uma string legível para o usuário."""
        if not stats:
            return f"Estatísticas para '{title}' não encontradas."
            
        header = f" ESTATÍSTICAS: {title.upper()} ".center(80, "=")
        
        # Seções
        summary = (
            f"📊 RESUMO:\n"
            f"   - Concluídas: {stats.total_requests} (✅ {stats.successful_requests} Sucesso | ❌ {stats.failed_requests} Falhas)\n"
            f"   - Tempo Total: {stats.processing_time:.2f}s\n"
            f"   - Taxa de Sucesso: {stats.success_rate:.1f}%\n"
        )
        
        performance = (
            f"⏱️ DESEMPENHO:\n"
            f"   - Taxa Média: {stats.avg_rate:.2f} reqs/s\n"
            f"   - Latência Média da API: {stats.avg_api_latency * 1000:.0f} ms/req\n"
            f"   - Pico de Concorrência: {stats.concurrent_peak} requisições\n"
        )

        cost_consumption = (
            f"💰 CUSTO E CONSUMO:\n"
            f"   - Custo Total: ${stats.total_cost:.4f}\n"
            f"   - Custo Médio por Req: ${stats.avg_cost_per_request:.6f}\n"
            f"   - Total de Tokens: {stats.total_tokens:,} (In: {stats.total_input_tokens:,} | Out: {stats.total_output_tokens:,} | Cached: {stats.total_cached_tokens:,})\n"
        )

        reliability = (
            f"🛡️ CONFIABILIDADE E EFICIÊNCIA:\n"
            f"   - Retries Totais: {stats.total_retry_count}\n"
            f"   - Erros de Rate Limit da API: {stats.api_rate_limits_detected}\n"
            f"   - Pausas Proativas: {stats.proactive_pauses} (totalizando {stats.total_proactive_wait_time:.2f}s)\n"
            f"   - Pausas Forçadas por Erro: {stats.global_rate_limit_activations} (totalizando {stats.total_global_wait_time:.2f}s)\n"
        )

        if stats.failed_requests > 0:
            error_breakdown = "   - Breakdown de Erros:\n"
            for error, count in stats.error_type_counts.most_common():
                error_breakdown += f"     - {error}: {count}\n"
            reliability += error_breakdown

        footer = "=" * 80
        
        return f"\n{header}\n\n{summary}\n{performance}\n{cost_consumption}\n{reliability}\n{footer}\n"
