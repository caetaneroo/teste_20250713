import asyncio
import time
import logging
import statistics
from collections import Counter
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List

logger = logging.getLogger(__name__)

@dataclass
class StatsContainer:
    """
    Um contÃªiner de dados otimizado para armazenar e calcular mÃ©tricas de
    desempenho e custo de forma precisa e eficiente.
    """
    # --- IdentificaÃ§Ã£o e Tempo ---
    id: str
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    # --- Contadores de RequisiÃ§Ã£o ---
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    error_type_counts: Counter = field(default_factory=Counter)
    total_retry_count: int = 0

    # --- Contadores de Tokens e Custo ---
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    total_cached_tokens: int = 0
    total_cost: float = 0.0

    # --- Rastreamento de LatÃªncia (CorreÃ§Ã£o) ---
    api_response_times: List[float] = field(default_factory=list)

    # --- Rastreamento de ConcorrÃªncia (CorreÃ§Ã£o) ---
    current_concurrent_requests: int = 0
    concurrent_peak: int = 0  # O pico real observado
    configured_max_concurrency: int = 0 # O Ãºltimo limite definido pelo RateLimiter

    # --- MÃ©tricas de Rate Limiter ---
    api_rate_limits_detected: int = 0
    proactive_pauses: int = 0
    total_proactive_wait_time: float = 0.0
    global_rate_limit_activations: int = 0
    total_global_wait_time: float = 0.0
    
    # --- Propriedades Calculadas (Refinadas) ---
    @property
    def processing_time(self) -> float:
        """Calcula o tempo total de processamento do contÃªiner (lote ou global)."""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

    @property
    def total_tokens(self) -> int:
        return self.total_input_tokens + self.total_output_tokens

    @property
    def success_rate(self) -> float:
        if self.total_requests > 0:
            return (self.successful_requests / self.total_requests) * 100
        return 100.0

    # --- Novas Propriedades para Min, Max, MÃ©dia ---
    @property
    def min_api_latency(self) -> float:
        """Retorna a latÃªncia mÃ­nima da API, em milissegundos."""
        return min(self.api_response_times) * 1000 if self.api_response_times else 0

    @property
    def max_api_latency(self) -> float:
        """Retorna a latÃªncia mÃ¡xima da API, em milissegundos."""
        return max(self.api_response_times) * 1000 if self.api_response_times else 0

    @property
    def avg_api_latency(self) -> float:
        """Retorna a latÃªncia mÃ©dia da API, em milissegundos."""
        return statistics.mean(self.api_response_times) * 1000 if self.api_response_times else 0


class StatsManager:
    """
    Gerenciador centralizado para coletar, calcular e apresentar estatÃ­sticas.
    """

    def __init__(self, models_config: Dict[str, Any]):
        self._models_config = models_config
        self._global_stats = StatsContainer(id="global")
        self._batch_stats: Dict[str, StatsContainer] = {}
        self._lock = asyncio.Lock()
        logger.info("StatsManager inicializado e pronto para coletar mÃ©tricas.")

    def _get_model_pricing(self, model: str) -> Dict[str, float]:
        """ObtÃ©m os preÃ§os de um modelo a partir da configuraÃ§Ã£o carregada."""
        model_data = self._models_config.get(model, {})
        return {
            'input': model_data.get('input', 0.0),
            'output': model_data.get('output', 0.0),
            'cache': model_data.get('cache', 0.0)
        }

    def _calculate_cost(
        self, model: str, input_tokens: int, output_tokens: int, cached_tokens: int = 0
    ) -> float:
        """Calcula o custo total de uma requisiÃ§Ã£o."""
        pricing = self._get_model_pricing(model)
        regular_input = max(0, input_tokens - cached_tokens)
        return ((regular_input / 1000) * pricing['input'] +
                (cached_tokens / 1000) * pricing['cache'] +
                (output_tokens / 1000) * pricing['output'])

    async def _update_stats(self, stats: StatsContainer, **kwargs):
        """FunÃ§Ã£o auxiliar para atualizar um contÃªiner de estatÃ­sticas de forma segura."""
        stats.total_requests += 1
        
        if kwargs.get('success', False):
            stats.successful_requests += 1
        else:
            stats.failed_requests += 1
            stats.error_type_counts[kwargs.get('error_type', 'UnknownError')] += 1
        
        cost = self._calculate_cost(
            model=kwargs['model'],
            input_tokens=kwargs.get('input_tokens', 0),
            output_tokens=kwargs.get('output_tokens', 0),
            cached_tokens=kwargs.get('cached_tokens', 0)
        )
        stats.total_cost += cost

        stats.total_input_tokens += kwargs.get('input_tokens', 0)
        stats.total_output_tokens += kwargs.get('output_tokens', 0)
        stats.total_cached_tokens += kwargs.get('cached_tokens', 0)
        
        # Armazena o tempo de resposta individual para cÃ¡lculos de min/max/mÃ©dia
        if (api_time := kwargs.get('api_response_time', 0.0)) > 0:
            stats.api_response_times.append(api_time)
            
        stats.total_retry_count += kwargs.get('retry_count', 0)

    async def record_request(self, batch_id: Optional[str] = None, **kwargs):
        """Registra os dados de uma Ãºnica requisiÃ§Ã£o finalizada."""
        async with self._lock:
            await self._update_stats(self._global_stats, **kwargs)
            if batch_id and batch_id in self._batch_stats:
                await self._update_stats(self._batch_stats[batch_id], **kwargs)

    async def record_rate_limiter_event(self, event: Dict[str, Any], batch_id: Optional[str] = None):
        """Registra eventos vindos do RateLimiter."""
        event_type = event.get('event_type')
        async with self._lock:
            containers = [self._global_stats]
            if batch_id and batch_id in self._batch_stats:
                containers.append(self._batch_stats[batch_id])

            for stats in containers:
                if event_type == 'proactive_pause':
                    stats.proactive_pauses += 1
                    stats.total_proactive_wait_time += event.get('wait_time', 0.0)
                elif event_type == 'api_rate_limit_detected':
                     stats.api_rate_limits_detected += 1
                elif event_type == 'concurrency_update':
                    stats.configured_max_concurrency = event.get('new_concurrency', 0)
    
    async def record_concurrent_start(self, batch_id: Optional[str] = None):
        """Registra o inÃ­cio de uma requisiÃ§Ã£o para rastrear a concorrÃªncia."""
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests += 1
                if stats.current_concurrent_requests > stats.concurrent_peak:
                    stats.concurrent_peak = stats.current_concurrent_requests

    async def record_concurrent_end(self, batch_id: Optional[str] = None):
        """Registra o fim de uma requisiÃ§Ã£o."""
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests -= 1

    def _get_relevant_containers(self, batch_id: Optional[str]) -> List[StatsContainer]:
        """Retorna os contÃªineres de estatÃ­sticas relevantes (global e, se houver, de lote)."""
        containers = [self._global_stats]
        if batch_id and batch_id in self._batch_stats:
            containers.append(self._batch_stats[batch_id])
        return containers

    def start_batch(self, batch_id: str):
        """Inicia um novo contÃªiner de estatÃ­sticas para um lote."""
        if batch_id in self._batch_stats:
            logger.warning(f"Batch com ID '{batch_id}' jÃ¡ existe. Sobrescrevendo estatÃ­sticas.")
        
        self._batch_stats[batch_id] = StatsContainer(id=batch_id)
        logger.info(f"Lote de estatÃ­sticas '{batch_id}' iniciado.")

    def end_batch(self, batch_id: str) -> Optional[StatsContainer]:
        """Finaliza um lote, registrando o tempo de tÃ©rmino."""
        if batch_id in self._batch_stats:
            self._batch_stats[batch_id].end_time = time.time()
            return self._batch_stats[batch_id]
        logger.warning(f"Tentativa de finalizar lote inexistente: '{batch_id}'")
        return None

    def get_global_stats(self) -> StatsContainer:
        return self._global_stats

    def get_batch_stats(self, batch_id: str) -> Optional[StatsContainer]:
        return self._batch_stats.get(batch_id)

    def format_stats(self, stats: StatsContainer, title: str) -> str:
        """Formata um contÃªiner de estatÃ­sticas em uma string legÃ­vel para o usuÃ¡rio."""
        if not stats:
            return f"EstatÃ­sticas para '{title}' nÃ£o encontradas."
            
        header = f" ESTATÃSTICAS: {title.upper()} ".center(80, "=")
        
        # SeÃ§Ãµes
        summary = (
            f"ðŸ“Š RESUMO GERAL:\n"
            f"   - RequisiÃ§Ãµes Totais: {stats.total_requests} (âœ… {stats.successful_requests} Sucesso | âŒ {stats.failed_requests} Falhas)\n"
            f"   - Tempo Total do Lote: {stats.processing_time:.2f}s\n" # CorreÃ§Ã£o 1
            f"   - Taxa de Sucesso: {stats.success_rate:.1f}%\n"
        )
        
        performance = (
            f"â±ï¸ DESEMPENHO E LATÃŠNCIA:\n"
            f"   - LatÃªncia API (min/mÃ©dia/max): {stats.min_api_latency:.0f}ms / {stats.avg_api_latency:.0f}ms / {stats.max_api_latency:.0f}ms\n" # CorreÃ§Ã£o 3
            f"   - Pico de ConcorrÃªncia Real: {stats.concurrent_peak} requisiÃ§Ãµes\n" # CorreÃ§Ã£o 2
            f"   - ConcorrÃªncia Configurada (alvo): {stats.configured_max_concurrency} requisiÃ§Ãµes\n" # CorreÃ§Ã£o 2
        )

        cost_consumption = (
            f"ðŸ’° CUSTO E CONSUMO DE TOKENS:\n"
            f"   - Custo Total Estimado: ${stats.total_cost:.4f}\n"
            f"   - Total de Tokens: {stats.total_tokens:,} (Input: {stats.total_input_tokens:,} | Output: {stats.total_output_tokens:,} | Cache: {stats.total_cached_tokens:,})\n"
        )

        reliability = (
            f"ðŸ›¡ï¸ CONFIABILIDADE E EFICIÃŠNCIA DO RATE LIMITER:\n"
            f"   - Retries Totais: {stats.total_retry_count}\n"
            f"   - Erros de Rate Limit da API: {stats.api_rate_limits_detected}\n"
            f"   - Pausas Proativas: {stats.proactive_pauses} (totalizando {stats.total_proactive_wait_time:.2f}s)\n"
        )

        if stats.failed_requests > 0:
            error_breakdown = "   - Breakdown de Erros:\n"
            for error, count in stats.error_type_counts.most_common():
                error_breakdown += f"     - {error}: {count}\n"
            reliability += error_breakdown

        footer = "=" * 80
        
        return f"\n{header}\n\n{summary}\n{performance}\n{cost_consumption}\n{reliability}\n{footer}\n"

