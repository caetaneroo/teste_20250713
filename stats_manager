import asyncio
import time
import logging
import statistics
from collections import Counter
from dataclasses import dataclass, field
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

@dataclass
class StatsContainer:
    """
    Um contêiner de dados robusto e otimizado para armazenar e calcular métricas
    de desempenho, com timestamps formatados e insights de paralelização.
    """
    # --- Identificação e Tempo ---
    id: str
    start_time: float = field(default_factory=time.time)
    end_time: Optional[float] = None

    # --- Contadores de Requisição ---
    total_requests: int = 0
    successful_requests: int = 0
    failed_requests: int = 0
    error_type_counts: Counter = field(default_factory=Counter)
    total_retry_count: int = 0

    # --- Contadores de Tokens e Custo ---
    total_input_tokens: int = 0
    total_output_tokens: int = 0
    total_cached_tokens: int = 0
    total_cost: float = 0.0

    # --- Rastreamento de Latência ---
    api_response_times: List[float] = field(default_factory=list)

    # --- Rastreamento de Concorrência ---
    current_concurrent_requests: int = 0
    concurrent_peak: int = 0
    configured_max_concurrency: int = 0

    # --- Métricas de Rate Limiter ---
    api_rate_limits_detected: int = 0  # **CORREÇÃO DEFINITIVA**: Atributo re-adicionado.
    proactive_pauses: int = 0
    total_proactive_wait_time: float = 0.0
    
    # --- Propriedades Calculadas ---
    @property
    def processing_time(self) -> float:
        """Tempo real decorrido do início ao fim (tempo de relógio)."""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

    @property
    def total_api_time(self) -> float:
        """Soma de todos os tempos de resposta da API (tempo serial)."""
        return sum(self.api_response_times)

    @property
    def parallelization_gain_seconds(self) -> float:
        """Calcula a economia de tempo em segundos obtida com a paralelização."""
        if self.processing_time > 0:
            return self.total_api_time - self.processing_time
        return 0.0

    @property
    def parallelization_gain_percent(self) -> float:
        """Calcula a economia de tempo em porcentagem."""
        if self.total_api_time > 0:
            return (self.parallelization_gain_seconds / self.total_api_time) * 100
        return 0.0
        
    @property
    def min_api_latency(self) -> float:
        return min(self.api_response_times) if self.api_response_times else 0

    @property
    def max_api_latency(self) -> float:
        return max(self.api_response_times) if self.api_response_times else 0

    @property
    def avg_api_latency(self) -> float:
        return statistics.mean(self.api_response_times) if self.api_response_times else 0

    # --- Propriedades para Timestamps Formatados ---
    @staticmethod
    def _format_brt(timestamp: float) -> str:
        """Converte um timestamp Unix para uma string no Horário de Brasília (UTC-3)."""
        if not timestamp:
            return "N/A"
        brt_time = datetime.fromtimestamp(timestamp) - timedelta(hours=3)
        return brt_time.strftime('%Y-%m-%d %H:%M:%S')

    @property
    def start_time_brt(self) -> str:
        """Retorna o timestamp de início formatado."""
        return self._format_brt(self.start_time)

    @property
    def end_time_brt(self) -> str:
        """Retorna o timestamp de fim formatado."""
        return self._format_brt(self.end_time)


class StatsManager:
    """
    Gerenciador centralizado para coletar, calcular e apresentar estatísticas,
    com uma interface simplificada e robusta para o usuário.
    """

    def __init__(self, models_config: Dict[str, Any]):
        self._models_config = models_config
        self._global_stats = StatsContainer(id="global")
        self._batch_stats: Dict[str, StatsContainer] = {}
        self._lock = asyncio.Lock()
        logger.info("StatsManager inicializado e pronto para gerar insights.")

    def _get_model_pricing(self, model: str) -> Dict[str, float]:
        model_data = self._models_config.get(model, {})
        return {'input': model_data.get('input', 0.0), 'output': model_data.get('output', 0.0), 'cache': model_data.get('cache', 0.0)}

    def _calculate_cost(self, model: str, input_tokens: int, output_tokens: int, cached_tokens: int = 0) -> float:
        pricing = self._get_model_pricing(model)
        regular_input = max(0, input_tokens - cached_tokens)
        return ((regular_input / 1000) * pricing['input'] + (cached_tokens / 1000) * pricing['cache'] + (output_tokens / 1000) * pricing['output'])

    async def _update_stats(self, stats: StatsContainer, **kwargs):
        stats.total_requests += 1
        if kwargs.get('success', False):
            stats.successful_requests += 1
        else:
            stats.failed_requests += 1
            stats.error_type_counts[kwargs.get('error_type', 'UnknownError')] += 1
        
        cost = self._calculate_cost(model=kwargs['model'], input_tokens=kwargs.get('input_tokens', 0), output_tokens=kwargs.get('output_tokens', 0), cached_tokens=kwargs.get('cached_tokens', 0))
        stats.total_cost += cost
        stats.total_input_tokens += kwargs.get('input_tokens', 0)
        stats.total_output_tokens += kwargs.get('output_tokens', 0)
        stats.total_cached_tokens += kwargs.get('cached_tokens', 0)
        if (api_time := kwargs.get('api_response_time', 0.0)) > 0:
            stats.api_response_times.append(api_time)
        stats.total_retry_count += kwargs.get('retry_count', 0)

    async def record_request(self, batch_id: Optional[str] = None, **kwargs):
        async with self._lock:
            await self._update_stats(self._global_stats, **kwargs)
            if batch_id and batch_id in self._batch_stats:
                await self._update_stats(self._batch_stats[batch_id], **kwargs)

    async def record_rate_limiter_event(self, event: Dict[str, Any], batch_id: Optional[str] = None):
        event_type = event.get('event_type')
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                if event_type == 'proactive_pause':
                    stats.proactive_pauses += 1
                    stats.total_proactive_wait_time += event.get('wait_time', 0.0)
                elif event_type == 'api_rate_limit_detected':
                     stats.api_rate_limits_detected += 1
                elif event_type == 'concurrency_update':
                    stats.configured_max_concurrency = event.get('new_concurrency', 0)
    
    async def record_concurrent_start(self, batch_id: Optional[str] = None):
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests += 1
                if stats.current_concurrent_requests > stats.concurrent_peak:
                    stats.concurrent_peak = stats.current_concurrent_requests

    async def record_concurrent_end(self, batch_id: Optional[str] = None):
        async with self._lock:
            for stats in self._get_relevant_containers(batch_id):
                stats.current_concurrent_requests -= 1

    def _get_relevant_containers(self, batch_id: Optional[str]) -> List[StatsContainer]:
        containers = [self._global_stats]
        if batch_id and batch_id in self._batch_stats:
            containers.append(self._batch_stats[batch_id])
        return containers

    def start_batch(self, batch_id: str):
        if batch_id in self._batch_stats:
            logger.warning(f"Batch com ID '{batch_id}' já existe. Sobrescrevendo estatísticas.")
        self._batch_stats[batch_id] = StatsContainer(id=batch_id)
        logger.info(f"Lote de estatísticas '{batch_id}' iniciado.")

    def end_batch(self, batch_id: str) -> Optional[StatsContainer]:
        if batch_id in self._batch_stats:
            self._batch_stats[batch_id].end_time = time.time()
            return self._batch_stats[batch_id]
        return None

    def _format_stats(self, stats: StatsContainer, title: str) -> str:
        """Formata um contêiner de estatísticas em uma string legível e rica em insights."""
        header = f" RELATÓRIO DE PERFORMANCE: {title.upper()} ".center(80, "=")
        
        summary = (
            f"📊 RESUMO GERAL:\n"
            f"   - Requisições Totais: {stats.total_requests} (✅ {stats.successful_requests} Sucesso | ❌ {stats.failed_requests} Falhas)\n"
            f"   - Início: {stats.start_time_brt} | Fim: {stats.end_time_brt}\n"
            f"   - Duração Total: {stats.processing_time:.2f}s\n"
        )
        
        parallelization = (
            f"🚀 EFICIÊNCIA DA PARALELIZAÇÃO:\n"
            f"   - Tempo Total de API (Serial): {stats.total_api_time:.2f}s\n"
            f"   - Ganho com Paralelização: {stats.parallelization_gain_seconds:.2f}s ({stats.parallelization_gain_percent:.1f}% de economia de tempo)\n"
        )

        performance = (
            f"⏱️ DESEMPENHO E LATÊNCIA:\n"
            f"   - Latência API (min/média/max): {stats.min_api_latency:.1f}s / {stats.avg_api_latency:.1f}s / {stats.max_api_latency:.1f}s\n"
            f"   - Concorrência Configurada (Alvo): {stats.configured_max_concurrency} requisições\n"
            f"   - Pico de Concorrência (Real): {stats.concurrent_peak} requisições\n"
        )

        cost_consumption = (
            f"💰 CUSTO E CONSUMO DE TOKENS:\n"
            f"   - Custo Total Estimado: ${stats.total_cost:.4f}\n"
            f"   - Total de Tokens: {stats.total_input_tokens + stats.total_output_tokens:,}\n"
        )

        reliability = (
            f"🛡️ CONFIABILIDADE E RATE LIMITER:\n"
            f"   - Retries Totais: {stats.total_retry_count}\n"
            f"   - Erros de Rate Limit da API: {stats.api_rate_limits_detected}\n"
            f"   - Pausas Proativas: {stats.proactive_pauses} (totalizando {stats.total_proactive_wait_time:.2f}s)\n"
        )

        footer = "=" * 80
        
        # **CORREÇÃO**: Explicação de concorrência removida do retorno final.
        return (f"\n{header}\n\n{summary}\n{parallelization}\n{performance}\n{cost_consumption}\n{reliability}\n{footer}\n")

    def get_summary(self, batch_id: Optional[str] = None) -> str:
        """
        Retorna uma string formatada com o resumo completo das estatísticas
        para um lote específico ou para as estatísticas globais.
        """
        if batch_id:
            stats = self._batch_stats.get(batch_id)
            title = f"LOTE {batch_id}"
            if not stats:
                return f"Erro: Nenhuma estatística encontrada para o lote com ID '{batch_id}'."
        else:
            stats = self._global_stats
            title = "GLOBAL"
        
        return self._format_stats(stats, title)
