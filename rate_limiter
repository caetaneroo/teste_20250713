# core/rate_limiter.py

import asyncio
import time
import logging
import re
from typing import Dict, Any
from collections import deque
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class TokenUsageRecord:
    estimated_tokens: int
    actual_tokens: int
    timestamp: float
    accuracy_ratio: float

class AdaptiveRateLimiter:
    """
    Rate limiter com calibra√ß√£o adaptativa e integra√ß√£o com stats_manager.
    - Foca em adapta√ß√£o din√¢mica baseada em execu√ß√µes reais para maximizar throughput sem rate limits.
    - N√£o gerencia stats internamente; reporta para stats_manager.
    - Logs minimizados para eventos relevantes apenas.
    - Tratamento reativo para erros de rate limit: extrai tempo de espera da resposta de erro e aplica pausa global.
    - Unifica√ß√£o de limites: usa tpm_limit como base, com buffer din√¢mico (inicial 90%, ajust√°vel via tend√™ncias).
    """

    def __init__(self, tpm_limit: int = 125000, calibration_enabled: bool = True, buffer_percentage: float = 0.9):
        self.tpm_limit = tpm_limit
        self.effective_tpm = int(tpm_limit * buffer_percentage)  # Buffer inicial para seguran√ßa, ajust√°vel dinamicamente
        self.tokens_used_this_minute = 0
        self.minute_start = time.time()
        self._lock = asyncio.Lock()
        self.calibration_enabled = calibration_enabled
        self.usage_history = deque(maxlen=1000)  # Hist√≥rico limitado para efici√™ncia de mem√≥ria
        self.calibration_factor = 1.0
        self.min_factor = 0.3
        self.max_factor = 3.0
        self.last_recalibration = time.time()
        self.recalibration_interval = 300  # Recalibra a cada 5min
        self._global_rate_limit_active = False
        self._global_wait_until = 0.0
        self._rate_limit_lock = asyncio.Lock()
        self._current_batch_id = None
        self.api_rate_limits_detected = 0
        self.prevented_rate_limits = 0
        self.utilization_history = deque(maxlen=60)  # Hist√≥rico de utiliza√ß√£o por minuto para ajustes din√¢micos

        logger.info(
            "AdaptiveRateLimiter inicializado",
            extra={
                'tpm_limit': tpm_limit,
                'effective_tpm': self.effective_tpm,
                'calibration_enabled': calibration_enabled,
                'action': 'rate_limiter_init'
            }
        )

    def start_batch(self, batch_id: str) -> None:
        self._current_batch_id = batch_id
        self.api_rate_limits_detected = 0
        logger.debug(f"Rate limiter preparado para batch {batch_id}", extra={'batch_id': batch_id, 'action': 'batch_rate_limit_start'})

    def record_token_usage(self, estimated_tokens: int, actual_tokens: int) -> None:
        """Registra uso para calibra√ß√£o, mas stats s√£o gerenciadas externamente."""
        if not self.calibration_enabled or actual_tokens <= 0 or estimated_tokens <= 0:
            return
        accuracy_ratio = actual_tokens / estimated_tokens
        self.usage_history.append(TokenUsageRecord(estimated_tokens, actual_tokens, time.time(), accuracy_ratio))
        if time.time() - self.last_recalibration > self.recalibration_interval:
            self._recalibrate_factor()

    def _recalibrate_factor(self) -> None:
        """Recalibra com weighted average, priorizando dados recentes."""
        if len(self.usage_history) < 20:
            return
        recent_history = list(self.usage_history)[-200:]
        total_weight = sum((i + 1) / len(recent_history) for i in range(len(recent_history)))
        weighted_sum = sum(record.accuracy_ratio * ((i + 1) / len(recent_history)) for i, record in enumerate(recent_history))
        avg_accuracy = weighted_sum / total_weight if total_weight > 0 else 1.0
        new_factor = (avg_accuracy * 0.6) + (self.calibration_factor * 0.4)
        self.calibration_factor = max(self.min_factor, min(self.max_factor, new_factor))
        self.last_recalibration = time.time()

    def get_calibrated_estimate(self, base_estimate: int) -> int:
        return int(base_estimate * self.calibration_factor) if self.calibration_enabled else base_estimate

    async def wait_for_tokens(self, estimated_tokens: int) -> int:
        """Espera por tokens com pausas proativas baseadas em effective_tpm, ajustando buffer dinamicamente."""
        async with self._rate_limit_lock:
            current_time = time.time()
            if self._global_rate_limit_active and current_time < self._global_wait_until:
                wait_time = self._global_wait_until - current_time
                if wait_time > 5:  # Log apenas pausas significativas
                    logger.warning(f"üö® Pausa global de {wait_time:.1f}s para evitar rate limit", extra={'wait_time': round(wait_time, 1), 'action': 'global_pause'})
                await asyncio.sleep(wait_time)
                self._global_rate_limit_active = False

            calibrated_tokens = self.get_calibrated_estimate(estimated_tokens)
            async with self._lock:
                current_time = time.time()
                if current_time - self.minute_start >= 60:
                    # Registra utiliza√ß√£o do minuto anterior e ajusta buffer
                    utilization = (self.tokens_used_this_minute / self.tpm_limit) * 100 if self.tpm_limit > 0 else 0
                    self.utilization_history.append(utilization)
                    self._adjust_buffer()
                    self.tokens_used_this_minute = 0
                    self.minute_start = current_time
                if self.tokens_used_this_minute + calibrated_tokens > self.effective_tpm:
                    wait_time = 60 - (current_time - self.minute_start)
                    if wait_time > 0:
                        logger.warning(f"‚è≥ Pausa proativa de {wait_time:.1f}s para manter abaixo do limite efetivo", extra={'wait_time': round(wait_time, 1), 'action': 'proactive_pause'})
                        await asyncio.sleep(wait_time)
                        self.tokens_used_this_minute = 0
                        self.minute_start = time.time()
                        self.prevented_rate_limits += 1
            return calibrated_tokens

    def _adjust_buffer(self) -> None:
        """Ajusta buffer dinamicamente baseado em tend√™ncias de utiliza√ß√£o (ex.: reduz se baixa para maximizar throughput)."""
        if len(self.utilization_history) < 5:
            return
        avg_utilization = sum(self.utilization_history) / len(self.utilization_history)
        if avg_utilization < 70:
            new_buffer = min(0.95, (self.effective_tpm / self.tpm_limit) + 0.05)  # Aumenta effective_tpm
        elif avg_utilization > 90:
            new_buffer = max(0.85, (self.effective_tpm / self.tpm_limit) - 0.05)  # Reduz para mais seguran√ßa
        else:
            new_buffer = 0.9
        self.effective_tpm = int(self.tpm_limit * new_buffer)

    async def activate_global_rate_limit(self, wait_time: float):
        """Ativa pausa global apenas quando necess√°rio."""
        async with self._rate_limit_lock:
            current_time = time.time()
            new_wait_until = current_time + wait_time
            if new_wait_until > self._global_wait_until:
                self._global_rate_limit_active = True
                self._global_wait_until = new_wait_until
                self.api_rate_limits_detected += 1
                if wait_time > 5:
                    logger.warning(f"üö® Pausa global ativada por erro de rate limit: {wait_time:.1f}s", extra={'wait_time': round(wait_time, 1), 'action': 'global_rate_limit_activated'})

    def extract_wait_time_from_error(self, error_result: Dict[str, Any]) -> float:
        """Extrai tempo de espera de erro de rate limit, com fallback."""
        if 'retry_after' in error_result:
            try:
                return float(error_result['retry_after'])
            except (ValueError, TypeError):
                pass

        error_msg = error_result.get('error', '').lower()
        patterns = [
            r'retry after (\d+) seconds',
            r'wait (\d+) seconds',
            r'retry.*?(\d+)\s*seconds?',
            r'(\d+)s',
            r'retry.*?(\d+)',
            r'wait.*?(\d+)'
        ]
        for pattern in patterns:
            match = re.search(pattern, error_msg, re.IGNORECASE)
            if match:
                try:
                    return float(match.group(1))
                except (ValueError, IndexError):
                    continue

        if 'response_headers' in error_result:
            headers = error_result['response_headers']
            if 'retry-after' in headers:
                try:
                    return float(headers['retry-after'])
                except (ValueError, TypeError):
                    pass

        return 60.0  # Fallback conservador

    def record_tokens(self, tokens_used: int) -> None:
        self.tokens_used_this_minute += tokens_used

    def get_status(self) -> Dict[str, Any]:
        """Retorna status para integra√ß√£o com stats_manager."""
        current_time = time.time()
        time_in_minute = current_time - self.minute_start
        utilization = (self.tokens_used_this_minute / self.effective_tpm) * 100 if self.effective_tpm > 0 else 0
        return {
            'tokens_used': self.tokens_used_this_minute,
            'effective_tpm': self.effective_tpm,
            'utilization_percent': round(utilization, 2),
            'time_in_minute': round(time_in_minute, 2),
            'prevented_rate_limits': self.prevented_rate_limits,
            'api_rate_limits_detected': self.api_rate_limits_detected,
            'calibration_factor': round(self.calibration_factor, 3)
        }
